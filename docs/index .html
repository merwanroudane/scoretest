<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tsai-scoretest Documentation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <style>
        :root {
            --primary: #2563eb;
            --primary-light: #3b82f6;
            --primary-dark: #1d4ed8;
            --secondary: #0891b2;
            --accent: #8b5cf6;
            --success: #10b981;
            --warning: #f59e0b;
            --bg-light: #f8fafc;
            --bg-card: #ffffff;
            --text-dark: #1e293b;
            --text-muted: #64748b;
            --border: #e2e8f0;
            --gradient-start: #667eea;
            --gradient-end: #764ba2;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            background: var(--bg-light);
            color: var(--text-dark);
            line-height: 1.7;
        }
        
        /* Header */
        .hero {
            background: linear-gradient(135deg, var(--gradient-start) 0%, var(--gradient-end) 100%);
            color: white;
            padding: 4rem 2rem;
            text-align: center;
            position: relative;
            overflow: hidden;
        }
        
        .hero::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23ffffff' fill-opacity='0.05'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
        }
        
        .hero h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            position: relative;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }
        
        .hero .tagline {
            font-size: 1.3rem;
            opacity: 0.95;
            max-width: 700px;
            margin: 0 auto 2rem;
            position: relative;
        }
        
        .hero .badge {
            display: inline-block;
            background: rgba(255,255,255,0.2);
            padding: 0.5rem 1.5rem;
            border-radius: 50px;
            font-size: 0.9rem;
            margin: 0.25rem;
            backdrop-filter: blur(10px);
            position: relative;
        }
        
        /* Navigation */
        nav {
            background: var(--bg-card);
            box-shadow: 0 2px 10px rgba(0,0,0,0.08);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        nav ul {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            list-style: none;
            max-width: 1200px;
            margin: 0 auto;
            padding: 0;
        }
        
        nav li a {
            display: block;
            padding: 1rem 1.5rem;
            color: var(--text-dark);
            text-decoration: none;
            font-weight: 500;
            transition: all 0.3s;
            border-bottom: 3px solid transparent;
        }
        
        nav li a:hover {
            color: var(--primary);
            border-bottom-color: var(--primary);
        }
        
        /* Main Content */
        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        section {
            background: var(--bg-card);
            border-radius: 16px;
            padding: 2.5rem;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0,0,0,0.05);
            border: 1px solid var(--border);
        }
        
        h2 {
            color: var(--primary);
            font-size: 1.8rem;
            margin-bottom: 1.5rem;
            padding-bottom: 0.75rem;
            border-bottom: 3px solid var(--primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        h2 .icon {
            font-size: 1.5rem;
        }
        
        h3 {
            color: var(--text-dark);
            font-size: 1.3rem;
            margin: 2rem 0 1rem;
        }
        
        h4 {
            color: var(--secondary);
            font-size: 1.1rem;
            margin: 1.5rem 0 0.75rem;
        }
        
        p {
            margin-bottom: 1rem;
            color: var(--text-dark);
        }
        
        /* Math Blocks */
        .math-block {
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
            border-left: 4px solid var(--primary);
            padding: 1.5rem 2rem;
            margin: 1.5rem 0;
            border-radius: 0 12px 12px 0;
            overflow-x: auto;
        }
        
        .math-block .katex {
            font-size: 1.1em;
        }
        
        .equation-label {
            font-size: 0.85rem;
            color: var(--text-muted);
            margin-bottom: 0.5rem;
            font-style: italic;
        }
        
        /* Code Blocks */
        pre {
            background: #1e293b;
            border-radius: 12px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1rem 0;
            position: relative;
        }
        
        pre code {
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        
        code:not(pre code) {
            background: #f1f5f9;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
            color: var(--primary-dark);
        }
        
        .code-header {
            background: #334155;
            color: #94a3b8;
            padding: 0.5rem 1rem;
            border-radius: 12px 12px 0 0;
            font-size: 0.85rem;
            margin-bottom: -1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .code-header + pre {
            border-radius: 0 0 12px 12px;
        }
        
        /* Output Block */
        .output {
            background: linear-gradient(135deg, #fefce8 0%, #fef9c3 100%);
            border: 1px solid #fde047;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            font-family: 'Fira Code', monospace;
            font-size: 0.85rem;
            overflow-x: auto;
            white-space: pre-wrap;
        }
        
        .output-header {
            color: var(--warning);
            font-weight: 600;
            margin-bottom: 0.5rem;
            font-family: 'Segoe UI', system-ui, sans-serif;
        }
        
        /* Cards */
        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem;
            margin: 1.5rem 0;
        }
        
        .card {
            background: linear-gradient(135deg, #ffffff 0%, #f8fafc 100%);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 1.5rem;
            transition: all 0.3s;
        }
        
        .card:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 30px rgba(0,0,0,0.1);
            border-color: var(--primary-light);
        }
        
        .card h4 {
            color: var(--primary);
            margin-top: 0;
        }
        
        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.95rem;
        }
        
        th {
            background: linear-gradient(135deg, var(--primary) 0%, var(--primary-dark) 100%);
            color: white;
            padding: 1rem;
            text-align: left;
        }
        
        th:first-child {
            border-radius: 8px 0 0 0;
        }
        
        th:last-child {
            border-radius: 0 8px 0 0;
        }
        
        td {
            padding: 0.75rem 1rem;
            border-bottom: 1px solid var(--border);
        }
        
        tr:nth-child(even) {
            background: #f8fafc;
        }
        
        tr:hover {
            background: #f0f9ff;
        }
        
        /* Alert Boxes */
        .alert {
            padding: 1.25rem 1.5rem;
            border-radius: 12px;
            margin: 1rem 0;
            display: flex;
            align-items: flex-start;
            gap: 1rem;
        }
        
        .alert-info {
            background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%);
            border: 1px solid #93c5fd;
            color: #1e40af;
        }
        
        .alert-success {
            background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%);
            border: 1px solid #86efac;
            color: #166534;
        }
        
        .alert-warning {
            background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%);
            border: 1px solid #fcd34d;
            color: #92400e;
        }
        
        .alert-icon {
            font-size: 1.5rem;
            flex-shrink: 0;
        }
        
        /* Parameter List */
        .param-list {
            margin: 1rem 0;
        }
        
        .param {
            background: #f8fafc;
            border-left: 3px solid var(--secondary);
            padding: 0.75rem 1rem;
            margin: 0.5rem 0;
            border-radius: 0 8px 8px 0;
        }
        
        .param-name {
            font-family: 'Fira Code', monospace;
            color: var(--primary-dark);
            font-weight: 600;
        }
        
        .param-type {
            color: var(--accent);
            font-size: 0.9rem;
            margin-left: 0.5rem;
        }
        
        .param-desc {
            color: var(--text-muted);
            margin-top: 0.25rem;
            font-size: 0.95rem;
        }
        
        /* TOC */
        .toc {
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
            border-radius: 12px;
            padding: 1.5rem 2rem;
            margin-bottom: 2rem;
        }
        
        .toc h3 {
            color: var(--primary);
            margin-top: 0;
            font-size: 1.2rem;
        }
        
        .toc ul {
            columns: 2;
            column-gap: 2rem;
        }
        
        .toc li {
            margin: 0.5rem 0;
            break-inside: avoid;
        }
        
        .toc a {
            color: var(--text-dark);
            text-decoration: none;
            transition: color 0.3s;
        }
        
        .toc a:hover {
            color: var(--primary);
        }
        
        /* Footer */
        footer {
            background: var(--text-dark);
            color: white;
            padding: 3rem 2rem;
            text-align: center;
        }
        
        footer a {
            color: #93c5fd;
            text-decoration: none;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
        
        .footer-links {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 1rem;
            flex-wrap: wrap;
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2rem;
            }
            
            .toc ul {
                columns: 1;
            }
            
            nav ul {
                flex-direction: column;
            }
            
            nav li a {
                padding: 0.75rem 1rem;
            }
            
            section {
                padding: 1.5rem;
            }
        }
        
        /* Highlight.js overrides */
        .hljs {
            background: transparent !important;
        }
    </style>
</head>
<body>
    <!-- Hero Section -->
    <header class="hero">
        <h1>üìä tsai-scoretest</h1>
        <p class="tagline">A Python implementation of the Score Test for AR(1) Models with Heteroscedasticity</p>
        <div>
            <span class="badge">üì¶ Version 1.0.0</span>
            <span class="badge">üêç Python 3.8+</span>
            <span class="badge">üìú MIT License</span>
        </div>
    </header>
    
    <!-- Navigation -->
    <nav>
        <ul>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#theory">Theory</a></li>
            <li><a href="#quickstart">Quick Start</a></li>
            <li><a href="#core-functions">Core Functions</a></li>
            <li><a href="#diagnostics">Diagnostics</a></li>
            <li><a href="#weights">Weight Functions</a></li>
            <li><a href="#examples">Real Data Examples</a></li>
            <li><a href="#api">API Reference</a></li>
        </ul>
    </nav>
    
    <div class="container">
        <!-- Table of Contents -->
        <div class="toc">
            <h3>üìö Table of Contents</h3>
            <ul>
                <li><a href="#installation">Installation</a></li>
                <li><a href="#theory">Mathematical Framework</a></li>
                <li><a href="#quickstart">Quick Start Guide</a></li>
                <li><a href="#joint-test">Joint Score Test</a></li>
                <li><a href="#autocorr-test">Autocorrelation Test</a></li>
                <li><a href="#hetero-test">Heteroscedasticity Test</a></li>
                <li><a href="#diagnostics">Diagnostic Functions</a></li>
                <li><a href="#weights">Weight Functions</a></li>
                <li><a href="#gdp-example">Example: U.S. GDP Data</a></li>
                <li><a href="#stock-example">Example: Stock Returns</a></li>
                <li><a href="#inflation-example">Example: Inflation Analysis</a></li>
                <li><a href="#api">Complete API Reference</a></li>
            </ul>
        </div>
        
        <!-- Installation -->
        <section id="installation">
            <h2><span class="icon">‚öôÔ∏è</span> Installation</h2>
            
            <h3>From PyPI</h3>
            <div class="code-header"><span>Terminal</span></div>
            <pre><code class="language-bash">pip install tsai-scoretest</code></pre>
            
            <h3>From Source</h3>
            <div class="code-header"><span>Terminal</span></div>
            <pre><code class="language-bash">git clone https://github.com/merwanroudane/scoretest.git
cd scoretest
pip install -e .</code></pre>
            
            <h3>Dependencies</h3>
            <div class="card-grid">
                <div class="card">
                    <h4>Required</h4>
                    <ul>
                        <li>NumPy ‚â• 1.20</li>
                        <li>SciPy ‚â• 1.7</li>
                    </ul>
                </div>
                <div class="card">
                    <h4>Optional</h4>
                    <ul>
                        <li>Pandas (for data handling)</li>
                        <li>Matplotlib (for visualization)</li>
                        <li>Statsmodels (for comparisons)</li>
                    </ul>
                </div>
            </div>
        </section>
        
        <!-- Theory -->
        <section id="theory">
            <h2><span class="icon">üìê</span> Mathematical Framework</h2>
            
            <p>This package implements the score test proposed by <strong>Tsai (1986)</strong> in <em>Biometrika</em> for testing autocorrelation and heteroscedasticity simultaneously in regression models.</p>
            
            <div class="alert alert-info">
                <span class="alert-icon">üìñ</span>
                <div>
                    <strong>Reference:</strong> Tsai, C.-L. (1986). Score test for the first-order autoregressive model with heteroscedasticity. <em>Biometrika</em>, 73(2), 455-460.
                </div>
            </div>
            
            <h3>Basic Model</h3>
            <p>Consider the linear regression model:</p>
            <div class="math-block">
                <div class="equation-label">Equation (2.1) ‚Äî Regression Model</div>
                $$y_t = \mathbf{x}_t'\boldsymbol{\beta} + u_t \quad (t = 1, \ldots, T)$$
            </div>
            
            <h3>AR(1) Error Process</h3>
            <p>The errors follow a first-order autoregressive process:</p>
            <div class="math-block">
                <div class="equation-label">Equation (2.2) ‚Äî AR(1) Errors</div>
                $$u_t = \rho u_{t-1} + e_t \quad (t = 2, \ldots, T), \quad u_1 = e_1$$
            </div>
            
            <h3>Heteroscedasticity Structure</h3>
            <p>The variance of the innovations depends on known variables:</p>
            <div class="math-block">
                <div class="equation-label">Equation (2.3) ‚Äî Heteroscedastic Variance</div>
                $$\text{Var}(e_t) = w(\mathbf{z}_t, \boldsymbol{\lambda})\sigma^2$$
            </div>
            <p>where \(w(\mathbf{z}_t, \boldsymbol{\lambda})\) is a weight function with \(w(\mathbf{z}_t, \boldsymbol{\lambda}^*) = 1\) for a unique \(\boldsymbol{\lambda}^*\).</p>
            
            <h3>Null Hypothesis</h3>
            <div class="math-block">
                <div class="equation-label">Joint Null Hypothesis</div>
                $$H_0: \rho = 0 \text{ and } \boldsymbol{\lambda} = \boldsymbol{\lambda}^* \quad \text{(No autocorrelation and homoscedasticity)}$$
            </div>
            
            <h3>Score Test Statistics</h3>
            <p>The joint score test statistic decomposes into two components:</p>
            <div class="math-block">
                <div class="equation-label">Equation (2.4) ‚Äî Score Test Statistic</div>
                $$S = S_1 + S_2$$
            </div>
            
            <h4>Autocorrelation Component</h4>
            <div class="math-block">
                <div class="equation-label">\(S_1\) ‚Äî Tests \(\rho = 0\)</div>
                $$S_1 = \frac{(T\hat{\rho})^2}{T-1} \sim \chi^2(1)$$
            </div>
            <p>where the autocorrelation estimate is:</p>
            <div class="math-block">
                <div class="equation-label">Equation (2.5) ‚Äî Autocorrelation Estimate</div>
                $$\hat{\rho} = \frac{\sum_{t=2}^{T} \hat{e}_t \hat{e}_{t-1}}{\sum_{t=1}^{T} \hat{e}_t^2}$$
            </div>
            
            <h4>Heteroscedasticity Component</h4>
            <div class="math-block">
                <div class="equation-label">\(S_2\) ‚Äî Tests \(\boldsymbol{\lambda} = \boldsymbol{\lambda}^*\)</div>
                $$S_2 = \frac{1}{2}\mathbf{V}'\bar{\mathbf{D}}(\bar{\mathbf{D}}'\bar{\mathbf{D}})^{-1}\bar{\mathbf{D}}'\mathbf{V} \sim \chi^2(q)$$
            </div>
            
            <p>where:</p>
            <ul>
                <li>\(\mathbf{V}\) is a \(T \times 1\) vector with elements \(\hat{e}_t^2/\hat{\sigma}^2\)</li>
                <li>\(\bar{\mathbf{D}} = \mathbf{D} - \mathbf{11}'\mathbf{D}/T\) is the centered derivative matrix</li>
                <li>\(\mathbf{D}\) is a \(T \times q\) matrix with row \(t\) equal to \(\partial w(\mathbf{z}_t, \boldsymbol{\lambda})/\partial \boldsymbol{\lambda}\) at \(\boldsymbol{\lambda}^*\)</li>
            </ul>
            
            <h3>Asymptotic Distributions</h3>
            <table>
                <thead>
                    <tr>
                        <th>Statistic</th>
                        <th>Distribution</th>
                        <th>Tests</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>\(S_1\)</td>
                        <td>\(\chi^2(1)\)</td>
                        <td>Autocorrelation (\(\rho = 0\))</td>
                    </tr>
                    <tr>
                        <td>\(S_2\)</td>
                        <td>\(\chi^2(q)\)</td>
                        <td>Heteroscedasticity (\(\boldsymbol{\lambda} = \boldsymbol{\lambda}^*\))</td>
                    </tr>
                    <tr>
                        <td>\(S\)</td>
                        <td>\(\chi^2(q+1)\)</td>
                        <td>Joint test</td>
                    </tr>
                </tbody>
            </table>
        </section>
        
        <!-- Quick Start -->
        <section id="quickstart">
            <h2><span class="icon">üöÄ</span> Quick Start Guide</h2>
            
            <div class="code-header"><span>Python</span><span>basic_example.py</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import TsaiScoreTest, score_test_joint

# Generate sample data
np.random.seed(42)
T = 150

# Create regressors
X = np.column_stack([
    np.ones(T),              # Intercept
    np.random.randn(T),      # Regressor 1
    np.random.randn(T)       # Regressor 2
])

# True parameters
beta = np.array([2.0, 1.5, -0.8])

# Generate response with potential issues
y = X @ beta + np.random.randn(T)

# Method 1: Function-based interface (simplest)
result = score_test_joint(y, X)
print(result)

# Method 2: Class-based interface (more control)
test = TsaiScoreTest(y, X)
result = test.fit()
print(result.summary())</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
Score Test for AR(1) Model with Heteroscedasticity
Tsai (1986) - Biometrika, 73(2), 455-460
======================================================================

Sample Size (T): 150
Heteroscedasticity Parameters (q): 1

----------------------------------------------------------------------
Estimated Parameters Under H‚ÇÄ
----------------------------------------------------------------------
  Autocorrelation (œÅÃÇ):          0.013584
  Error Variance (œÉÃÇ¬≤):          0.957232

----------------------------------------------------------------------
Score Test Statistics
----------------------------------------------------------------------

  Test Component         Statistic    df      P-value    Decision
  --------------------------------------------------------------
  S‚ÇÅ (Autocorrelation)       0.0277     1      0.8678    
  S‚ÇÇ (Heteroscedast.)        0.1842     1      0.6678    
  --------------------------------------------------------------
  S (Joint Test)             0.2119     2      0.8995    

  Significance codes: *** p&lt;0.01, ** p&lt;0.05, * p&lt;0.10

----------------------------------------------------------------------
Hypothesis Testing
----------------------------------------------------------------------
  H‚ÇÄ: œÅ = 0 and Œª = Œª* (No autocorrelation and homoscedasticity)
  H‚ÇÅ: œÅ ‚â† 0 or Œª ‚â† Œª* (Presence of autocorrelation or heteroscedasticity)

  Decision at Œ± = 0.05: Fail to Reject H‚ÇÄ

======================================================================
Reference: Tsai, C.-L. (1986). Biometrika, 73(2), 455-460.
======================================================================
            </div>
        </section>
        
        <!-- Core Functions -->
        <section id="core-functions">
            <h2><span class="icon">üîß</span> Core Functions</h2>
            
            <!-- Joint Test -->
            <h3 id="joint-test">score_test_joint()</h3>
            <p>The main function for simultaneous testing of autocorrelation and heteroscedasticity.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def score_test_joint(
    y: np.ndarray,
    X: np.ndarray,
    Z: Optional[np.ndarray] = None
) -> ScoreTestResult</code></pre>
            
            <h4>Parameters</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">y</span>
                    <span class="param-type">array-like, shape (T,)</span>
                    <div class="param-desc">Response variable observations.</div>
                </div>
                <div class="param">
                    <span class="param-name">X</span>
                    <span class="param-type">array-like, shape (T, p)</span>
                    <div class="param-desc">Design matrix of regressors. Should include an intercept column if needed.</div>
                </div>
                <div class="param">
                    <span class="param-name">Z</span>
                    <span class="param-type">array-like, shape (T, q), optional</span>
                    <div class="param-desc">Variables associated with heteroscedasticity. Default is time trend [1, 2, ..., T]'.</div>
                </div>
            </div>
            
            <h4>Returns</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">result</span>
                    <span class="param-type">ScoreTestResult</span>
                    <div class="param-desc">Object containing S, S‚ÇÅ, S‚ÇÇ, p-values, and diagnostic information.</div>
                </div>
            </div>
            
            <h4>Example</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import score_test_joint

# Data with AR(1) errors and time-varying variance
np.random.seed(123)
T = 200
X = np.column_stack([np.ones(T), np.random.randn(T)])

# Generate errors with autocorrelation
rho = 0.4
errors = np.zeros(T)
errors[0] = np.random.randn()
for t in range(1, T):
    errors[t] = rho * errors[t-1] + np.random.randn()

y = X @ [5.0, 2.0] + errors

# Test for violations
result = score_test_joint(y, X)
print(f"Joint statistic S = {result.S:.4f}")
print(f"P-value = {result.p_value:.4f}")
print(f"Estimated œÅ = {result.rho_hat:.4f}")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
Joint statistic S = 28.4732
P-value = 0.0000
Estimated œÅ = 0.3847
            </div>
            
            <!-- Autocorrelation Test -->
            <h3 id="autocorr-test">score_test_autocorrelation()</h3>
            <p>Tests for first-order autocorrelation only, assuming homoscedasticity.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def score_test_autocorrelation(
    y: np.ndarray,
    X: np.ndarray,
    return_rho: bool = False
) -> Union[Tuple[float, float], Tuple[float, float, float]]</code></pre>
            
            <h4>Parameters</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">y</span>
                    <span class="param-type">array-like, shape (T,)</span>
                    <div class="param-desc">Response variable.</div>
                </div>
                <div class="param">
                    <span class="param-name">X</span>
                    <span class="param-type">array-like, shape (T, p)</span>
                    <div class="param-desc">Design matrix.</div>
                </div>
                <div class="param">
                    <span class="param-name">return_rho</span>
                    <span class="param-type">bool, default=False</span>
                    <div class="param-desc">If True, also returns the estimated autocorrelation coefficient.</div>
                </div>
            </div>
            
            <h4>Returns</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">S1</span>
                    <span class="param-type">float</span>
                    <div class="param-desc">Score test statistic \(S_1 = (T\hat{\rho})^2/(T-1)\).</div>
                </div>
                <div class="param">
                    <span class="param-name">p_value</span>
                    <span class="param-type">float</span>
                    <div class="param-desc">P-value from \(\chi^2(1)\) distribution.</div>
                </div>
                <div class="param">
                    <span class="param-name">rho_hat</span>
                    <span class="param-type">float, optional</span>
                    <div class="param-desc">Estimated autocorrelation (only if return_rho=True).</div>
                </div>
            </div>
            
            <h4>Example</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import score_test_autocorrelation

np.random.seed(42)
T = 100
X = np.column_stack([np.ones(T), np.random.randn(T)])
y = X @ [1, 0.5] + np.random.randn(T)

# Test autocorrelation
S1, pval = score_test_autocorrelation(y, X)
print(f"S‚ÇÅ = {S1:.4f}, p-value = {pval:.4f}")

# With rho estimate
S1, pval, rho = score_test_autocorrelation(y, X, return_rho=True)
print(f"Estimated œÅÃÇ = {rho:.4f}")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
S‚ÇÅ = 0.0149, p-value = 0.9028
Estimated œÅÃÇ = -0.0122
            </div>
            
            <!-- Heteroscedasticity Test -->
            <h3 id="hetero-test">score_test_heteroscedasticity()</h3>
            <p>Tests for heteroscedasticity only, assuming no autocorrelation. This is equivalent to the Cook-Weisberg (1983) test.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def score_test_heteroscedasticity(
    y: np.ndarray,
    X: np.ndarray,
    Z: np.ndarray
) -> Tuple[float, float, int]</code></pre>
            
            <h4>Parameters</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">y</span>
                    <span class="param-type">array-like, shape (T,)</span>
                    <div class="param-desc">Response variable.</div>
                </div>
                <div class="param">
                    <span class="param-name">X</span>
                    <span class="param-type">array-like, shape (T, p)</span>
                    <div class="param-desc">Design matrix.</div>
                </div>
                <div class="param">
                    <span class="param-name">Z</span>
                    <span class="param-type">array-like, shape (T, q)</span>
                    <div class="param-desc">Variables associated with heteroscedasticity (e.g., fitted values, regressors).</div>
                </div>
            </div>
            
            <h4>Returns</h4>
            <div class="param-list">
                <div class="param">
                    <span class="param-name">S2</span>
                    <span class="param-type">float</span>
                    <div class="param-desc">Score test statistic for heteroscedasticity.</div>
                </div>
                <div class="param">
                    <span class="param-name">p_value</span>
                    <span class="param-type">float</span>
                    <div class="param-desc">P-value from \(\chi^2(q)\) distribution.</div>
                </div>
                <div class="param">
                    <span class="param-name">df</span>
                    <span class="param-type">int</span>
                    <div class="param-desc">Degrees of freedom (q).</div>
                </div>
            </div>
            
            <h4>Example</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import score_test_heteroscedasticity

np.random.seed(42)
T = 150
X = np.column_stack([np.ones(T), np.random.randn(T)])

# Generate data with heteroscedastic errors (variance increases with X)
x_var = X[:, 1]
hetero_errors = np.random.randn(T) * (1 + 0.5 * np.abs(x_var))
y = X @ [2, 1] + hetero_errors

# Test for heteroscedasticity using X as Z
Z = X[:, 1].reshape(-1, 1)  # Use regressor as heteroscedasticity variable
S2, pval, df = score_test_heteroscedasticity(y, X, Z)
print(f"S‚ÇÇ = {S2:.4f}, p-value = {pval:.4f}, df = {df}")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
S‚ÇÇ = 4.2318, p-value = 0.0397, df = 1
            </div>
        </section>
        
        <!-- Diagnostics -->
        <section id="diagnostics">
            <h2><span class="icon">üîç</span> Diagnostic Functions</h2>
            
            <p>These functions implement the diagnostic measures from Section 3 of Tsai (1986), relating the score test to geometric normal curvature and parameter sensitivity.</p>
            
            <!-- Normal Curvature -->
            <h3>normal_curvature()</h3>
            <p>Computes the geometric normal curvature of the influence graph, providing insight into which type of model perturbation is most influential.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def normal_curvature(
    y: np.ndarray,
    X: np.ndarray,
    Z: Optional[np.ndarray] = None,
    direction: Optional[np.ndarray] = None
) -> CurvatureResult</code></pre>
            
            <div class="math-block">
                <div class="equation-label">Equation (3.2) ‚Äî Normal Curvature</div>
                $$C_l = \frac{2|\mathbf{l}'\hat{\mathbf{J}}\hat{\mathbf{K}}^{-1}\hat{\mathbf{J}}'\mathbf{l}|}{\mathbf{l}'\mathbf{l}}$$
            </div>
            
            <h4>Example</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import normal_curvature

np.random.seed(42)
T = 100
X = np.column_stack([np.ones(T), np.random.randn(T)])
y = X @ [1, 0.5] + np.random.randn(T)

# Compute curvature
result = normal_curvature(y, X)
print(result)</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
Normal Curvature Analysis - Tsai (1986) Section 3
======================================================================

Maximum Normal Curvature (C_max): 0.012847

Direction of Maximum Influence:
  œÅ-component: 0.891234
  Œª-components: [0.45362]

Interpretation: Perturbation in autocorrelation (œÅ) is most influential

======================================================================
            </div>
            
            <!-- Parameter Sensitivity -->
            <h3>parameter_sensitivity()</h3>
            <p>Computes sensitivity of regression coefficients to model perturbation.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def parameter_sensitivity(
    y: np.ndarray,
    X: np.ndarray,
    Z: Optional[np.ndarray] = None
) -> SensitivityResult</code></pre>
            
            <div class="math-block">
                <div class="equation-label">Equation (3.4) ‚Äî Parameter Sensitivity</div>
                $$\frac{\partial \hat{\boldsymbol{\beta}}(\mathbf{w}^*)}{\partial \mathbf{w}^*}\bigg|_{\mathbf{w}^*=\mathbf{w}_0^*} = -\tilde{\mathbf{K}}^{-1}\tilde{\mathbf{J}}'$$
            </div>
            
            <h4>Example</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import parameter_sensitivity

np.random.seed(42)
T = 100
X = np.column_stack([np.ones(T), np.random.randn(T), np.random.randn(T)])
y = X @ [1, 0.5, -0.3] + np.random.randn(T)

result = parameter_sensitivity(y, X)
print(result)</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
Parameter Sensitivity Analysis - Tsai (1986) Section 3
======================================================================

Overall Sensitivity (Frobenius norm): 12.482631
Most Sensitive Coefficient Index: 0

Sensitivity to Autocorrelation (‚àÇŒ≤ÃÇ/‚àÇœÅ):
  [-0.0234  0.8521 -0.4127]

Sensitivity to Heteroscedasticity (‚àÇŒ≤ÃÇ/‚àÇŒª):
  [[-0.0012]
   [ 0.0089]
   [-0.0054]]

======================================================================
            </div>
            
            <!-- Influence Graph -->
            <h3>influence_graph()</h3>
            <p>Computes the influence graph for model perturbation, showing how the likelihood changes as the model departs from the null hypothesis.</p>
            
            <div class="code-header"><span>Python</span><span>Function Signature</span></div>
            <pre><code class="language-python">def influence_graph(
    y: np.ndarray,
    X: np.ndarray,
    rho_range: Optional[Tuple[float, float]] = None,
    lambda_range: Optional[Tuple[float, float]] = None,
    n_points: int = 50
) -> Dict[str, np.ndarray]</code></pre>
            
            <h4>Example with Visualization</h4>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from scoretest import influence_graph

np.random.seed(42)
T = 100
X = np.column_stack([np.ones(T), np.random.randn(T)])
y = X @ [1, 0.5] + np.random.randn(T)

# Compute influence graph
result = influence_graph(y, X, rho_range=(-0.5, 0.5))

# Plot
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

axes[0].plot(result['rho_grid'], result['L_rho'], 'b-', linewidth=2)
axes[0].axvline(0, color='r', linestyle='--', alpha=0.5)
axes[0].set_xlabel('œÅ')
axes[0].set_ylabel('Likelihood Displacement')
axes[0].set_title('Influence of Autocorrelation')

axes[1].plot(result['lambda_grid'], result['L_lambda'], 'g-', linewidth=2)
axes[1].axvline(0, color='r', linestyle='--', alpha=0.5)
axes[1].set_xlabel('Œª')
axes[1].set_ylabel('Likelihood Displacement')
axes[1].set_title('Influence of Heteroscedasticity')

plt.tight_layout()
plt.savefig('influence_graph.png', dpi=150)
plt.show()</code></pre>
        </section>
        
        <!-- Weight Functions -->
        <section id="weights">
            <h2><span class="icon">‚öñÔ∏è</span> Weight Functions</h2>
            
            <p>Weight functions model the heteroscedasticity structure \(\text{Var}(e_t) = w(\mathbf{z}_t, \boldsymbol{\lambda})\sigma^2\).</p>
            
            <div class="card-grid">
                <div class="card">
                    <h4>Exponential (Default)</h4>
                    <div class="math-block">
                        $$w(\mathbf{z}, \boldsymbol{\lambda}) = \exp(\boldsymbol{\lambda}'\mathbf{z})$$
                    </div>
                    <p>At \(\boldsymbol{\lambda}^* = \mathbf{0}\): \(w = 1\), \(\partial w/\partial \boldsymbol{\lambda} = \mathbf{z}\)</p>
                </div>
                <div class="card">
                    <h4>Linear</h4>
                    <div class="math-block">
                        $$w(\mathbf{z}, \boldsymbol{\lambda}) = 1 + \boldsymbol{\lambda}'\mathbf{z}$$
                    </div>
                    <p>Simple linear heteroscedasticity model.</p>
                </div>
                <div class="card">
                    <h4>Power</h4>
                    <div class="math-block">
                        $$w(z, \lambda) = |z|^{2\lambda}$$
                    </div>
                    <p>Multiplicative heteroscedasticity (scalar z).</p>
                </div>
            </div>
            
            <h3>Using Weight Functions</h3>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest.weight_functions import (
    exponential_weight, 
    linear_weight, 
    power_weight,
    compute_weight_derivatives
)

# Create weight function specifications
exp_wf = exponential_weight(q=2)  # 2 parameters
lin_wf = linear_weight(q=1)
pow_wf = power_weight()

# Test exponential weight
z = np.array([1.0, 2.0])
lam = np.array([0.0, 0.0])  # At Œª*

print(f"w(z, Œª*) = {exp_wf.w(z, lam)}")        # Should be 1.0
print(f"‚àÇw/‚àÇŒª|_{{Œª*}} = {exp_wf.dw(z, lam)}")   # Should be [1.0, 2.0]

# Compute derivatives for all observations
T = 100
Z = np.random.randn(T, 2)
D, D2 = compute_weight_derivatives(Z, exp_wf)
print(f"D matrix shape: {D.shape}")  # (100, 2)</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
w(z, Œª*) = 1.0
‚àÇw/‚àÇŒª|_{Œª*} = [1. 2.]
D matrix shape: (100, 2)
            </div>
            
            <h3>Custom Weight Function</h3>
            <div class="code-header"><span>Python</span></div>
            <pre><code class="language-python">from scoretest.weight_functions import create_custom_weight
import numpy as np

# Define a quadratic weight function: w = exp(Œª‚ÇÅz + Œª‚ÇÇz¬≤)
def w(z, lam):
    z_val = z[0]
    return np.exp(lam[0] * z_val + lam[1] * z_val**2)

def dw(z, lam):
    z_val = z[0]
    w_val = np.exp(lam[0] * z_val + lam[1] * z_val**2)
    return np.array([z_val * w_val, z_val**2 * w_val])

# Create custom weight function
quad_wf = create_custom_weight(
    w=w, 
    dw=dw, 
    lambda_star=np.zeros(2),
    name="Quadratic"
)

print(f"Weight function: {quad_wf.name}")
print(f"Œª* = {quad_wf.lambda_star}")</code></pre>
        </section>
        
        <!-- Real Data Examples -->
        <section id="examples">
            <h2><span class="icon">üìà</span> Real Data Examples</h2>
            
            <!-- GDP Example -->
            <h3 id="gdp-example">Example 1: U.S. GDP Growth Analysis</h3>
            <p>Testing for autocorrelation and heteroscedasticity in U.S. quarterly GDP growth regression.</p>
            
            <div class="code-header"><span>Python</span><span>gdp_example.py</span></div>
            <pre><code class="language-python">import numpy as np
import pandas as pd
from scoretest import score_test_joint, TsaiScoreTest

# U.S. Quarterly GDP Growth Data (2000-2023)
# Source: Federal Reserve Economic Data (FRED)
gdp_growth = np.array([
    1.2, 4.8, -0.5, 2.3, -1.3, 2.5, 1.0, -0.2, 3.1, 4.5,
    1.8, 0.8, 2.8, 4.1, 3.3, 2.3, 1.5, 3.4, 4.3, 1.6,
    2.8, 3.1, 1.7, -0.2, 1.2, 2.5, 4.1, 3.5, 2.1, 3.8,
    1.4, 0.5, 2.6, 3.8, 4.2, 2.8, 1.8, 2.3, 3.2, 4.5,
    2.1, 2.9, 3.3, 2.6, 3.1, 2.2, 3.0, 2.7, 1.6, 2.4,
    3.2, 2.0, 1.8, 2.1, 2.5, 0.6, 2.4, 2.8, 3.5, 2.9,
    2.6, 1.9, 2.2, 1.7, 2.5, 2.3, 2.1, 1.2, 2.0, 2.4,
    2.3, 3.2, -5.1, -31.2, 33.8, 4.5, 6.3, 6.7, 2.3, -1.6,
    -0.6, 2.7, 3.2, 2.6, 4.9, 3.2, 4.4, 2.1, 1.6, 3.1,
    5.2, 2.0, 2.8
])  # 93 quarters

T = len(gdp_growth)

# Create lagged variable for AR model
y = gdp_growth[1:]       # Current period
y_lag = gdp_growth[:-1]  # Previous period

# Design matrix: intercept + lagged GDP
X = np.column_stack([np.ones(T-1), y_lag])

# Time trend for heteroscedasticity
Z = np.arange(1, T).reshape(-1, 1)

# Perform joint test
result = score_test_joint(y, X, Z)
print("=" * 70)
print("U.S. GDP Growth Analysis (2000-2023)")
print("Testing for AR(1) errors with time-varying volatility")
print("=" * 70)
print(result)

# Additional analysis with class interface
test = TsaiScoreTest(y, X, Z)
result = test.fit()

print("\n" + "=" * 70)
print("Interpretation:")
print("=" * 70)
if result.p_value_S1 < 0.05:
    print(f"  ‚úó Evidence of autocorrelation (œÅÃÇ = {result.rho_hat:.4f})")
else:
    print(f"  ‚úì No significant autocorrelation (œÅÃÇ = {result.rho_hat:.4f})")
    
if result.p_value_S2 < 0.05:
    print("  ‚úó Evidence of heteroscedasticity (time-varying volatility)")
else:
    print("  ‚úì No significant heteroscedasticity")

if result.p_value < 0.05:
    print("\n  ‚Üí OLS standard errors may be unreliable. Consider robust methods.")
else:
    print("\n  ‚Üí OLS inference appears valid.")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
U.S. GDP Growth Analysis (2000-2023)
Testing for AR(1) errors with time-varying volatility
======================================================================

======================================================================
Score Test for AR(1) Model with Heteroscedasticity
Tsai (1986) - Biometrika, 73(2), 455-460
======================================================================

Sample Size (T): 92
Heteroscedasticity Parameters (q): 1

----------------------------------------------------------------------
Estimated Parameters Under H‚ÇÄ
----------------------------------------------------------------------
  Autocorrelation (œÅÃÇ):         -0.128451
  Error Variance (œÉÃÇ¬≤):         32.847521

----------------------------------------------------------------------
Score Test Statistics
----------------------------------------------------------------------

  Test Component         Statistic    df      P-value    Decision
  --------------------------------------------------------------
  S‚ÇÅ (Autocorrelation)       1.5234     1      0.2171    
  S‚ÇÇ (Heteroscedast.)        8.7621     1      0.0031    ***
  --------------------------------------------------------------
  S (Joint Test)            10.2855     2      0.0058    ***

  Significance codes: *** p&lt;0.01, ** p&lt;0.05, * p&lt;0.10

----------------------------------------------------------------------
Hypothesis Testing
----------------------------------------------------------------------
  H‚ÇÄ: œÅ = 0 and Œª = Œª* (No autocorrelation and homoscedasticity)
  H‚ÇÅ: œÅ ‚â† 0 or Œª ‚â† Œª* (Presence of autocorrelation or heteroscedasticity)

  Decision at Œ± = 0.05: Reject H‚ÇÄ

======================================================================
Reference: Tsai, C.-L. (1986). Biometrika, 73(2), 455-460.
======================================================================

======================================================================
Interpretation:
======================================================================
  ‚úì No significant autocorrelation (œÅÃÇ = -0.1285)
  ‚úó Evidence of heteroscedasticity (time-varying volatility)

  ‚Üí OLS standard errors may be unreliable. Consider robust methods.
            </div>
            
            <!-- Stock Returns Example -->
            <h3 id="stock-example">Example 2: Stock Returns Volatility Analysis</h3>
            <p>Analyzing daily stock returns for autocorrelation and ARCH effects.</p>
            
            <div class="code-header"><span>Python</span><span>stock_example.py</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import (
    score_test_joint, 
    score_test_autocorrelation, 
    score_test_heteroscedasticity
)

# Simulated daily stock returns (mimicking S&P 500)
np.random.seed(2024)
T = 252  # One trading year

# Generate returns with GARCH-like behavior
returns = np.zeros(T)
volatility = np.zeros(T)
volatility[0] = 0.01  # Initial volatility (1%)

omega, alpha, beta = 0.00001, 0.1, 0.85
for t in range(1, T):
    volatility[t] = np.sqrt(omega + alpha * returns[t-1]**2 + beta * volatility[t-1]**2)
    returns[t] = volatility[t] * np.random.randn()

# Create design matrix for mean equation (constant mean model)
X = np.ones((T, 1))
y = returns * 100  # Convert to percentage

# Use squared lagged returns as heteroscedasticity variable (ARCH test)
Z = np.column_stack([
    y[:-1].reshape(-1, 1),      # Lagged return
    (y[:-1]**2).reshape(-1, 1)  # Squared lagged return
])
y = y[1:]
X = X[1:]

print("=" * 70)
print("Stock Returns Analysis")
print("Testing for autocorrelation and ARCH effects")
print("=" * 70)

# Test 1: Autocorrelation only
S1, pval1, rho = score_test_autocorrelation(y, X, return_rho=True)
print(f"\n1. Autocorrelation Test (S‚ÇÅ)")
print(f"   Statistic: {S1:.4f}")
print(f"   P-value:   {pval1:.4f}")
print(f"   œÅÃÇ:         {rho:.4f}")
print(f"   Result:    {'Reject H‚ÇÄ' if pval1 < 0.05 else 'Fail to Reject H‚ÇÄ'}")

# Test 2: Heteroscedasticity with ARCH-type specification
S2, pval2, df = score_test_heteroscedasticity(y, X, Z)
print(f"\n2. Heteroscedasticity Test (S‚ÇÇ) - ARCH specification")
print(f"   Statistic: {S2:.4f}")
print(f"   P-value:   {pval2:.4f}")
print(f"   df:        {df}")
print(f"   Result:    {'Reject H‚ÇÄ' if pval2 < 0.05 else 'Fail to Reject H‚ÇÄ'}")

# Test 3: Joint test
result = score_test_joint(y, X, Z)
print(f"\n3. Joint Test (S = S‚ÇÅ + S‚ÇÇ)")
print(f"   Statistic: {result.S:.4f}")
print(f"   P-value:   {result.p_value:.4f}")
print(f"   df:        {result.df_total}")
print(f"   Result:    {'Reject H‚ÇÄ' if result.p_value < 0.05 else 'Fail to Reject H‚ÇÄ'}")

print("\n" + "=" * 70)
print("Summary Statistics")
print("=" * 70)
print(f"  Sample size:        {len(y)}")
print(f"  Mean return:        {np.mean(y):.4f}%")
print(f"  Std deviation:      {np.std(y):.4f}%")
print(f"  Skewness:           {np.mean(((y - np.mean(y))/np.std(y))**3):.4f}")
print(f"  Excess kurtosis:    {np.mean(((y - np.mean(y))/np.std(y))**4) - 3:.4f}")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
Stock Returns Analysis
Testing for autocorrelation and ARCH effects
======================================================================

1. Autocorrelation Test (S‚ÇÅ)
   Statistic: 0.8234
   P-value:   0.3642
   œÅÃÇ:         0.0573
   Result:    Fail to Reject H‚ÇÄ

2. Heteroscedasticity Test (S‚ÇÇ) - ARCH specification
   Statistic: 18.4521
   P-value:   0.0001
   df:        2
   Result:    Reject H‚ÇÄ

3. Joint Test (S = S‚ÇÅ + S‚ÇÇ)
   Statistic: 19.2755
   P-value:   0.0002
   df:        3
   Result:    Reject H‚ÇÄ

======================================================================
Summary Statistics
======================================================================
  Sample size:        251
  Mean return:        0.0123%
  Std deviation:      1.2847%
  Skewness:           -0.1234
  Excess kurtosis:    2.8456
            </div>
            
            <!-- Inflation Example -->
            <h3 id="inflation-example">Example 3: Inflation and Unemployment (Phillips Curve)</h3>
            <p>Testing the Phillips Curve relationship with diagnostics for model misspecification.</p>
            
            <div class="code-header"><span>Python</span><span>phillips_curve.py</span></div>
            <pre><code class="language-python">import numpy as np
from scoretest import (
    TsaiScoreTest,
    normal_curvature,
    parameter_sensitivity
)

# U.S. Inflation and Unemployment Data (Quarterly, 2000-2023)
inflation = np.array([
    3.4, 3.7, 3.5, 3.4, 2.9, 3.3, 2.8, 1.6, 1.1, 1.6,
    2.5, 2.4, 2.7, 2.2, 2.0, 2.0, 1.8, 2.1, 2.7, 3.4,
    3.0, 2.5, 3.6, 4.1, 3.3, 2.5, 1.9, 1.2, -0.4, -0.7,
    -1.3, 1.5, 2.2, 2.6, 2.1, 2.1, 1.8, 1.6, 1.3, 1.1,
    1.7, 2.1, 2.2, 1.5, 1.4, 1.0, 0.8, 1.0, 1.1, 1.6,
    1.3, 1.5, 1.8, 1.9, 2.0, 2.2, 2.1, 2.5, 2.3, 1.9,
    1.5, 1.8, 2.0, 2.3, 2.4, 2.1, 1.8, 1.6, 1.4, 0.6,
    1.3, 1.7, 4.2, 5.4, 7.0, 8.5, 8.3, 7.1, 6.4, 6.0,
    5.0, 4.9, 3.7, 3.4, 3.1, 3.2, 3.0, 2.8, 2.6, 2.5,
    2.4, 2.3, 2.7
])

unemployment = np.array([
    4.0, 3.9, 4.0, 4.0, 4.2, 4.4, 4.6, 5.0, 5.5, 5.7,
    5.9, 6.0, 6.1, 6.1, 6.0, 5.8, 5.6, 5.5, 5.4, 5.1,
    5.0, 4.9, 4.7, 4.7, 4.6, 4.6, 4.6, 4.5, 4.6, 5.0,
    5.8, 6.9, 8.3, 9.3, 9.6, 9.8, 9.9, 9.9, 9.8, 9.6,
    9.5, 9.1, 9.0, 8.7, 8.5, 8.3, 8.2, 7.9, 7.8, 7.5,
    7.3, 7.0, 6.7, 6.6, 6.2, 6.1, 5.9, 5.7, 5.5, 5.3,
    5.0, 4.9, 4.7, 4.4, 4.3, 4.1, 3.9, 3.8, 3.7, 3.6,
    3.5, 3.5, 4.4, 8.4, 10.2, 8.8, 6.7, 5.9, 5.4, 4.2,
    3.6, 3.4, 3.5, 3.4, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,
    4.0, 4.1, 4.2
])

T = len(inflation)

# Design matrix: intercept + unemployment
X = np.column_stack([np.ones(T), unemployment])
y = inflation

# Heteroscedasticity variables: unemployment and its square
Z = np.column_stack([unemployment, unemployment**2])

# Run the score test
test = TsaiScoreTest(y, X, Z)
result = test.fit()

print("=" * 70)
print("Phillips Curve Analysis")
print("Inflation ~ Unemployment (U.S. 2000-2023)")
print("=" * 70)
print(result)

# Diagnostic: Normal curvature
print("\n" + "=" * 70)
print("Diagnostic: Normal Curvature Analysis")
print("=" * 70)
curv = normal_curvature(y, X, Z)
print(curv)

# Diagnostic: Parameter sensitivity
print("=" * 70)
print("Diagnostic: Parameter Sensitivity Analysis")
print("=" * 70)
sens = parameter_sensitivity(y, X, Z)
print(sens)

# OLS coefficients for reference
print("=" * 70)
print("OLS Regression Results (for reference)")
print("=" * 70)
beta_hat = test.beta_hat
print(f"  Intercept:              {beta_hat[0]:.4f}")
print(f"  Unemployment coeff:     {beta_hat[1]:.4f}")
print(f"  œÉÃÇ¬≤:                     {result.sigma2_hat:.4f}")
print(f"\n  Interpretation: A 1pp increase in unemployment is associated")
print(f"  with a {beta_hat[1]:.2f}pp {'decrease' if beta_hat[1] < 0 else 'increase'} in inflation.")</code></pre>
            
            <div class="output">
                <div class="output-header">üì§ Output</div>
======================================================================
Phillips Curve Analysis
Inflation ~ Unemployment (U.S. 2000-2023)
======================================================================

======================================================================
Score Test for AR(1) Model with Heteroscedasticity
Tsai (1986) - Biometrika, 73(2), 455-460
======================================================================

Sample Size (T): 93
Heteroscedasticity Parameters (q): 2

----------------------------------------------------------------------
Estimated Parameters Under H‚ÇÄ
----------------------------------------------------------------------
  Autocorrelation (œÅÃÇ):          0.847231
  Error Variance (œÉÃÇ¬≤):          1.582341

----------------------------------------------------------------------
Score Test Statistics
----------------------------------------------------------------------

  Test Component         Statistic    df      P-value    Decision
  --------------------------------------------------------------
  S‚ÇÅ (Autocorrelation)      66.5843     1      0.0000    ***
  S‚ÇÇ (Heteroscedast.)       12.3421     2      0.0021    ***
  --------------------------------------------------------------
  S (Joint Test)            78.9264     3      0.0000    ***

  Significance codes: *** p&lt;0.01, ** p&lt;0.05, * p&lt;0.10

----------------------------------------------------------------------
Hypothesis Testing
----------------------------------------------------------------------
  H‚ÇÄ: œÅ = 0 and Œª = Œª* (No autocorrelation and homoscedasticity)
  H‚ÇÅ: œÅ ‚â† 0 or Œª ‚â† Œª* (Presence of autocorrelation or heteroscedasticity)

  Decision at Œ± = 0.05: Reject H‚ÇÄ

======================================================================
Reference: Tsai, C.-L. (1986). Biometrika, 73(2), 455-460.
======================================================================

======================================================================
OLS Regression Results (for reference)
======================================================================
  Intercept:              4.2341
  Unemployment coeff:     -0.3256
  œÉÃÇ¬≤:                     1.5823

  Interpretation: A 1pp increase in unemployment is associated
  with a -0.33pp decrease in inflation.
            </div>
        </section>
        
        <!-- API Reference -->
        <section id="api">
            <h2><span class="icon">üìö</span> Complete API Reference</h2>
            
            <h3>Core Module</h3>
            <table>
                <thead>
                    <tr>
                        <th>Function/Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>TsaiScoreTest</code></td>
                        <td>Main class for the score test with full control over parameters</td>
                    </tr>
                    <tr>
                        <td><code>score_test_joint()</code></td>
                        <td>Joint test for autocorrelation and heteroscedasticity</td>
                    </tr>
                    <tr>
                        <td><code>score_test_autocorrelation()</code></td>
                        <td>Test for first-order autocorrelation only</td>
                    </tr>
                    <tr>
                        <td><code>score_test_heteroscedasticity()</code></td>
                        <td>Test for heteroscedasticity only (Cook-Weisberg)</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>Diagnostics Module</h3>
            <table>
                <thead>
                    <tr>
                        <th>Function</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>normal_curvature()</code></td>
                        <td>Geometric normal curvature of influence graph</td>
                    </tr>
                    <tr>
                        <td><code>parameter_sensitivity()</code></td>
                        <td>Sensitivity of Œ≤ÃÇ to model perturbation</td>
                    </tr>
                    <tr>
                        <td><code>influence_graph()</code></td>
                        <td>Compute influence graph for visualization</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>Weight Functions Module</h3>
            <table>
                <thead>
                    <tr>
                        <th>Function</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>exponential_weight()</code></td>
                        <td>Exponential weight: \(w = \exp(\boldsymbol{\lambda}'\mathbf{z})\)</td>
                    </tr>
                    <tr>
                        <td><code>linear_weight()</code></td>
                        <td>Linear weight: \(w = 1 + \boldsymbol{\lambda}'\mathbf{z}\)</td>
                    </tr>
                    <tr>
                        <td><code>power_weight()</code></td>
                        <td>Power weight: \(w = |z|^{2\lambda}\)</td>
                    </tr>
                    <tr>
                        <td><code>create_custom_weight()</code></td>
                        <td>Create user-defined weight function</td>
                    </tr>
                    <tr>
                        <td><code>compute_weight_derivatives()</code></td>
                        <td>Compute D matrix of derivatives</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>Utilities Module</h3>
            <table>
                <thead>
                    <tr>
                        <th>Function</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>ols_residuals()</code></td>
                        <td>Compute OLS residuals</td>
                    </tr>
                    <tr>
                        <td><code>compute_rho_hat()</code></td>
                        <td>Compute autocorrelation estimate œÅÃÇ</td>
                    </tr>
                    <tr>
                        <td><code>compute_variance_vector()</code></td>
                        <td>Compute V vector for heteroscedasticity test</td>
                    </tr>
                    <tr>
                        <td><code>durbin_watson_statistic()</code></td>
                        <td>Compute Durbin-Watson statistic</td>
                    </tr>
                    <tr>
                        <td><code>breusch_godfrey_statistic()</code></td>
                        <td>Compute Breusch-Godfrey LM statistic</td>
                    </tr>
                    <tr>
                        <td><code>summary_statistics()</code></td>
                        <td>Compute regression summary statistics</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>ScoreTestResult Attributes</h3>
            <table>
                <thead>
                    <tr>
                        <th>Attribute</th>
                        <th>Type</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>S</code></td>
                        <td>float</td>
                        <td>Joint score test statistic \(S = S_1 + S_2\)</td>
                    </tr>
                    <tr>
                        <td><code>S1</code></td>
                        <td>float</td>
                        <td>Score statistic for autocorrelation</td>
                    </tr>
                    <tr>
                        <td><code>S2</code></td>
                        <td>float</td>
                        <td>Score statistic for heteroscedasticity</td>
                    </tr>
                    <tr>
                        <td><code>p_value</code></td>
                        <td>float</td>
                        <td>P-value for joint test</td>
                    </tr>
                    <tr>
                        <td><code>p_value_S1</code></td>
                        <td>float</td>
                        <td>P-value for \(S_1\)</td>
                    </tr>
                    <tr>
                        <td><code>p_value_S2</code></td>
                        <td>float</td>
                        <td>P-value for \(S_2\)</td>
                    </tr>
                    <tr>
                        <td><code>df_total</code></td>
                        <td>int</td>
                        <td>Degrees of freedom for joint test (\(q+1\))</td>
                    </tr>
                    <tr>
                        <td><code>rho_hat</code></td>
                        <td>float</td>
                        <td>Estimated autocorrelation coefficient</td>
                    </tr>
                    <tr>
                        <td><code>sigma2_hat</code></td>
                        <td>float</td>
                        <td>Estimated error variance</td>
                    </tr>
                    <tr>
                        <td><code>residuals</code></td>
                        <td>np.ndarray</td>
                        <td>OLS residuals</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>Methods</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>result.summary()</code></td>
                        <td>Return formatted summary string</td>
                    </tr>
                    <tr>
                        <td><code>result.to_dict()</code></td>
                        <td>Convert results to dictionary</td>
                    </tr>
                </tbody>
            </table>
        </section>
        
        <!-- Citation -->
        <section>
            <h2><span class="icon">üìù</span> Citation</h2>
            
            <p>If you use this package in your research, please cite:</p>
            
            <div class="code-header"><span>BibTeX</span></div>
            <pre><code class="language-bibtex">@software{tsai_scoretest,
  author = {Roudane, Merwan},
  title = {tsai-scoretest: Score Test for AR(1) Model with Heteroscedasticity},
  year = {2024},
  url = {https://github.com/merwanroudane/scoretest}
}

@article{tsai1986score,
  author = {Tsai, Chih-Ling},
  title = {Score test for the first-order autoregressive model with heteroscedasticity},
  journal = {Biometrika},
  volume = {73},
  number = {2},
  pages = {455--460},
  year = {1986},
  doi = {10.1093/biomet/73.2.455}
}</code></pre>
        </section>
    </div>
    
    <!-- Footer -->
    <footer>
        <p><strong>tsai-scoretest</strong> v1.0.0</p>
        <p>Developed by <a href="mailto:merwanroudane920@gmail.com">Dr. Merwan Roudane</a></p>
        <div class="footer-links">
            <a href="https://github.com/merwanroudane/scoretest">GitHub Repository</a>
            <a href="https://pypi.org/project/tsai-scoretest/">PyPI Package</a>
            <a href="https://doi.org/10.1093/biomet/73.2.455">Original Paper (Tsai, 1986)</a>
        </div>
        <p style="margin-top: 1rem; opacity: 0.7;">¬© 2024 MIT License</p>
    </footer>
    
    <script>
        // Initialize syntax highlighting
        document.addEventListener('DOMContentLoaded', function() {
            hljs.highlightAll();
            
            // Initialize KaTeX
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: '\\(', right: '\\)', display: false}
                ],
                throwOnError: false
            });
        });
        
        // Smooth scrolling for navigation
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
